{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = 'NaN'\n",
    "csv_dict = {\n",
    "    'folder_name' : [],\n",
    "    'image_url' : [],\n",
    "    'class_name' : [],\n",
    "    'x1' : [],\n",
    "    'y1' :[],\n",
    "    '5': [],\n",
    "    '6' : [],\n",
    "    'x2' : [],\n",
    "    'y2' : [],\n",
    "    '9':[],\n",
    "    '10':[]\n",
    "\n",
    "\n",
    "}\n",
    "  \n",
    "### For reading lines \n",
    "def read_lines_from_file(file_name):\n",
    "      with open(file_name) as f:\n",
    "       lines = f.readlines()\n",
    "\n",
    "       return lines \n",
    "\n",
    "\n",
    "\n",
    "### Lines to Dict \n",
    "def lines_to_dict(lines):\n",
    "    for line in lines : \n",
    "        splited = line.split(' ')\n",
    "        class_index = splited.pop(0)\n",
    "        csv_dict['image_url'].insert(len(csv_dict['image_url']),'local_url')\n",
    "        csv_dict['folder_name'].insert(len(csv_dict['folder_name']),'TRAIN')\n",
    "        csv_dict['x1'].insert(len(csv_dict['x1']),splited[0])\n",
    "        csv_dict['y1'].insert(len(csv_dict['y1']),splited[2])\n",
    "        csv_dict['x2'].insert(len(csv_dict['x2']),splited[1])\n",
    "        csv_dict['y2'].insert(len(csv_dict['y2']),splited[3])\n",
    "        csv_dict['5'].insert(len(csv_dict['5']),nan_value)\n",
    "        csv_dict['6'].insert(len(csv_dict['6']),nan_value)\n",
    "        csv_dict['9'].insert(len(csv_dict['9']),nan_value)\n",
    "        csv_dict['10'].insert(len(csv_dict['10']),nan_value)\n",
    "    if class_index == '0':\n",
    "       csv_dict['class_name'].insert(len(csv_dict['class_name']),'fallen_trees')\n",
    "\n",
    "\n",
    "\n",
    "    if class_index == '1':\n",
    "       csv_dict['class_name'].insert(len(csv_dict['class_name']),'uncollected_waste')\n",
    "    \n",
    "    return csv_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def list_files_from_folder(relative_path):\n",
    "    \n",
    "    return os.listdir(relative_path)\n",
    "\n",
    "        \n",
    "    \n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 - read all file names from folder - done\n",
    "2- read all image file names from folder - done\n",
    "3- compare if images count = files count -   done\n",
    "4- \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list_files_from_folder('distortion_new')\n",
    "text_names = list_files_from_folder('label')\n",
    "print(len(image_names))\n",
    "print(len(text_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ext(file):\n",
    "    return os.path.splitext(file)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = [remove_ext(img) for img in image_names]\n",
    "txt_path = [remove_ext(txt) for txt in text_names]\n",
    "\n",
    "list(set(img_path) - set(txt_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_csv(dict):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    {'folder_name': ['TRAIN', 'TRAIN', 'TRAIN'],\n",
    "    'image_url': ['local_url', 'local_url', 'local_url'],\n",
    "    'class_name': ['fallen_trees', 'fallen_trees', 'fallen_trees'],\n",
    "    'x1': ['0.449549', '0.486999', '0.557636'],\n",
    "    'x2': ['0.496666', '0.495981', '0.493697'],\n",
    "    '5': ['NaN', 'NaN', 'NaN'],\n",
    "    '6': ['NaN', 'NaN', 'NaN'],\n",
    "    'y1': ['0.035318', '0.043235', '0.055413'],\n",
    "    'y2': ['0.015071\\n', '0.012788\\n', '0.010961'],\n",
    "    '9': ['NaN', 'NaN', 'NaN'],\n",
    "    '10': ['NaN', 'NaN', 'NaN']}\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    for key in dict : \n",
    "        print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in lines : \n",
    "    splited = line.split(' ')\n",
    "    class_index = splited.pop(0)\n",
    "    csv_dict['image_url'].insert(len(csv_dict['image_url']),'local_url')\n",
    "    csv_dict['folder_name'].insert(len(csv_dict['folder_name']),'TRAIN')\n",
    "    csv_dict['x1'].insert(len(csv_dict['x1']),splited[0])\n",
    "    csv_dict['y1'].insert(len(csv_dict['y1']),splited[2])\n",
    "    csv_dict['x2'].insert(len(csv_dict['x2']),splited[1])\n",
    "    csv_dict['y2'].insert(len(csv_dict['y2']),splited[3])\n",
    "    csv_dict['5'].insert(len(csv_dict['5']),nan_value)\n",
    "    csv_dict['6'].insert(len(csv_dict['6']),nan_value)\n",
    "    csv_dict['9'].insert(len(csv_dict['9']),nan_value)\n",
    "    csv_dict['10'].insert(len(csv_dict['10']),nan_value)\n",
    "    if class_index == '0':\n",
    "       csv_dict['class_name'].insert(len(csv_dict['class_name']),'fallen_trees')\n",
    "\n",
    "\n",
    "\n",
    "    if class_index == '1':\n",
    "       csv_dict['class_name'].insert(len(csv_dict['class_name']),'uncollected_waste')\n",
    "   \n",
    "    \n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(csv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_csv(csv_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_function(element):\n",
    "    print(element)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7b780c4e0938ffe1c50508eb9cf31911ab3c6d4fec4c1220ca8869b23d3816"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('model-makker': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
