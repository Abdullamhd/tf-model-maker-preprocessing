{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "labels_map = ['uncollected_waste','fallen_trees']\n",
    "\n",
    "\n",
    "def getfile_from_path(path):\n",
    "\n",
    "    file_names_with_ext = os.listdir(path)\n",
    "    base_names = []\n",
    "    file_names = []\n",
    "    for base in file_names_with_ext :\n",
    "        base_names.append(os.path.basename(line))\n",
    "    for name in base_names:\n",
    "        file_names.append(os.path.splitext(name)[0])\n",
    "    return file_names \n",
    "\n",
    "\n",
    "def get_different_filename(first_path,second_path):\n",
    "    list1 = getfile_from_path(first_path)\n",
    "    list2 = getfile_from_path(second_path)\n",
    "\n",
    "    return list(set(list1) - set(list2))\n",
    "\n",
    "\n",
    "\n",
    "def get_full_paths_of_files(dir_name):\n",
    "\n",
    "    names =os.listdir(dir_name)\n",
    "    full_paths = []\n",
    "\n",
    "    for name in names:\n",
    "\n",
    "        if '164949' in name :\n",
    "            print(name)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        path = dir_name + '/' +  name \n",
    "        full_paths.append(path)\n",
    "\n",
    "    for path in full_paths :\n",
    "        if not os.path.exists(path):\n",
    "            raise Exception('Path not exists')\n",
    "\n",
    "    \n",
    "    return full_paths\n",
    "\n",
    "def split_list(l,first_percentage,second_percentage):\n",
    "     i1=int(len(l) *first_percentage)\n",
    "     i2=int(len(l) *second_percentage)\n",
    "\n",
    "     train=[]\n",
    "     test=[]\n",
    "     validation=[]\n",
    "\n",
    "     for i in range (0,i1,1):\n",
    "        train.append(l[i])\n",
    "\n",
    "     for i in range (i1,i2,1):\n",
    "        test.append(l[i])\n",
    "\n",
    "     for i in range (i2,len(l) ,1):\n",
    "        validation.append(l[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     return (train, test, validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, shutil\n",
    "\n",
    "# For Images \n",
    "os.makedirs(\"distortion_detector/images/train\", exist_ok=True)\n",
    "os.makedirs(\"distortion_detector/images/test\", exist_ok=True)\n",
    "os.makedirs(\"distortion_detector/images/validation\", exist_ok=True)\n",
    "\n",
    "\n",
    "# For Annotations \n",
    "os.makedirs(\"distortion_detector/annotations/train\", exist_ok=True)\n",
    "os.makedirs(\"distortion_detector/annotations/test\", exist_ok=True)\n",
    "os.makedirs(\"distortion_detector/annotations/validation\", exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = get_full_paths_of_files('images_voc')\n",
    "annotations_paths = get_full_paths_of_files('annotations')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,validation = split_list(image_paths,.6,.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train set\n",
    "for t in train:\n",
    "    shutil.copy(t,'distortion_detector/images/train')\n",
    "    # shutil.copy(f'annotations/{t.replace(\"jpg\",\"xml\")}','distortion_detector/annotations/train')\n",
    "    t = t.replace('jpg','xml')\n",
    "    t = t.replace('images_voc','annotations')\n",
    "    shutil.copy(t,'distortion_detector/annotations/train')\n",
    "    \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy test set\n",
    "for t in test:\n",
    "    shutil.copy(t,'distortion_detector/images/test')\n",
    "    # shutil.copy(f'annotations/{t.replace(\"jpg\",\"xml\")}','distortion_detector/annotations/train')\n",
    "    t = t.replace('jpg','xml')\n",
    "    t = t.replace('images_voc','annotations')\n",
    "    shutil.copy(t,'distortion_detector/annotations/test')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy validation set\n",
    "for t in validation:\n",
    "\n",
    "    if '20210905_164949' in t :\n",
    "        print(t)\n",
    "\n",
    "    shutil.copy(t,'distortion_detector/images/validation')\n",
    "    # shutil.copy(f'annotations/{t.replace(\"jpg\",\"xml\")}','distortion_detector/annotations/train')\n",
    "    t = t.replace('jpg','xml')\n",
    "    t = t.replace('images_voc','annotations')\n",
    "    shutil.copy(t,'distortion_detector/annotations/validation')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy train annotations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = model_spec.get('efficientdet_lite0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Cache will be stored in /tmp/tmpzpl7rahz with prefix filename 7bee435cfee6949ada7cad38d32e815e. Cache_prefix is /tmp/tmpzpl7rahz/7bee435cfee6949ada7cad38d32e815e\n",
      "INFO:tensorflow:On image 0\n",
      "INFO:tensorflow:On image 100\n"
     ]
    }
   ],
   "source": [
    "train_data = object_detector.DataLoader.from_pascal_voc(images_dir='distortion_detector/images/train',annotations_dir='distortion_detector/annotations/train',label_map=labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Cache will be stored in /tmp/tmpzczlkq6_ with prefix filename fd42585a6188df7d3abc4e516ad0ebb5. Cache_prefix is /tmp/tmpzczlkq6_/fd42585a6188df7d3abc4e516ad0ebb5\n",
      "INFO:tensorflow:On image 0\n"
     ]
    }
   ],
   "source": [
    "test_data = object_detector.DataLoader.from_pascal_voc(images_dir='distortion_detector/images/test',annotations_dir='distortion_detector/annotations/test',label_map=labels_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Cache will be stored in /tmp/tmpotszgeq3 with prefix filename 670daa608bcf39c5564c3544f7316780. Cache_prefix is /tmp/tmpotszgeq3/670daa608bcf39c5564c3544f7316780\n",
      "INFO:tensorflow:On image 0\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "distortion_detector/images/validation/20210905_164949.jpg; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-90a6b219cba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pascal_voc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distortion_detector/images/validation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distortion_detector/annotations/validation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/abdullah/anaconda3/envs/model-makker/lib/python3.6/site-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader.py\u001b[0m in \u001b[0;36mfrom_pascal_voc\u001b[0;34m(cls, images_dir, annotations_dir, label_map, annotation_filenames, ignore_difficult_instances, num_shards, max_num_images, cache_dir, cache_prefix_filename)\u001b[0m\n\u001b[1;32m    218\u001b[0m           \u001b[0mcache_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m           \u001b[0mannotations_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m           annotation_filenames=annotation_filenames)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abdullah/anaconda3/envs/model-makker/lib/python3.6/site-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader_util.py\u001b[0m in \u001b[0;36mwrite_files\u001b[0;34m(self, cache_files, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m           \u001b[0mignore_difficult_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_difficult_instances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           ann_json_dict=ann_json_dict)\n\u001b[0m\u001b[1;32m    259\u001b[0m       \u001b[0mwriters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abdullah/anaconda3/envs/model-makker/lib/python3.6/site-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/dataset/create_pascal_tfrecord.py\u001b[0m in \u001b[0;36mdict_to_tf_example\u001b[0;34m(data, images_dir, label_map_dict, unique_id, ignore_difficult_instances, ann_json_dict)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0mfull_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mencoded_jpg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0mencoded_jpg_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_jpg_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abdullah/anaconda3/envs/model-makker/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/abdullah/anaconda3/envs/model-makker/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     79\u001b[0m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0;32m---> 80\u001b[0;31m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: distortion_detector/images/validation/20210905_164949.jpg; No such file or directory"
     ]
    }
   ],
   "source": [
    "validation_data = object_detector.DataLoader.from_pascal_voc(images_dir='distortion_detector/images/validation',annotations_dir='distortion_detector/annotations/validation',label_map=labels_map)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7b780c4e0938ffe1c50508eb9cf31911ab3c6d4fec4c1220ca8869b23d3816"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('model-makker': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
